\documentclass[11pt,letterpaper]{moderncv}

% moderncv themes
%\moderncvtheme[blue, roman]{casual}
% optional argument are 'blue' (default), 'orange', 'red', 'green', 'grey' and 'roman' (for roman fonts, instead of sans serif fonts)
\moderncvtheme[blue]{classic}                % idem

\usepackage[utf8]{inputenc}

% adjust the page margins
\usepackage[scale=0.8]{geometry}
\recomputelengths                             % required when changes are made to page layout lengths

% personal data
\firstname{Tom}
\familyname{Hart}
\title{Software Developer}
\input{contact.tex}


\nopagenumbers{}                             % uncomment to suppress automatic page numbering for CVs longer than one page

\begin{document}
\maketitle

\section{Skills}
\cventry{Languages}{Professional experience with Java, Go, C/C++, Python, and Ruby. Personal experience with Elixir and JavaScript}{}{}{}{}
\cventry{Other Skills}{GCP, AWS, Kubernetes, Terraform, JUnit, Mockito, Agile, Scrum, concurrency, git, Mercurial, ClearCase, ClearQuest, JIRA, Eclipse, XML, JSON, Cucumber, Maven, regular expressions}{}{}{}{}


\section{Experience}

\cventry{2018--present}
{Senior Backend Developer}
{ecobee}
{}{}
{
After the Switch+ launch, I proposed and built a service for collecting device-side metrics and storing them in Google BigQuery so that we could understand the performance of our devices. I subsequently moved off the Lighting squad, first working to make device authentication uniform and interoperable across our device types, then generalizing the infrastructure built for the Switch+ to support future products. I currently support backend systems for ecobee's thermostats, light switches, and cameras, and mentor other developers in these systems. \\
\textbf{Tools used:} Java, JUnit, Go, GCP, Kubernetes, Google PubSub, Google Spanner, Helm, Netty, Spring, Kafka, Eclipse, git, gradle, JIRA, Docker, AWS ECS, Terraform, MariaDB.
}

\cventry{2017--2018}
{Backend Developer}
{ecobee}
{}{}
{
I worked on the backend for the ecobee Switch+, becoming the development lead for the project during my first year at ecobee. On a technical level, this meant developing a service based on Netty for maintaining persistent TCP connections between the backend and the device fleet, building web-facing APIs using Spring Boot, and passing messages through the microservice-based backend using Kafka. Beyond my technical contributions to the backend, I worked with embedded and mobile developers to debug issues end-to-end and design interfaces between layers of the system. \\
\textbf{Tools used:} Java, JUnit, Go, Netty, Spring, Kafka, Eclipse, git, gradle, JIRA, Docker, AWS ECS, Terraform.
}

\cventry{2014--2017}
{Senior Software Developer}
{Rapid7}
{}{}
{
As a Senior Software Developer in the Data Collection and Assessment group, I have worked on high-performance concurrent data collection for the Nexpose scan engine, including scan engine pooling, multi-engine scanning, and agent-based data collection. I created infrastructure for transferring data from hosts to the cloud platform via the agent, and optimized the data collected, delivering an order of magnitude size reduction. As head of a team within this group, I was responsible for the Asset Configuration Export feature of Nexpose 6.0. As self-directed projects, I contributed automated vulnerability coverage for VMware Player, Workstation, and Fusion, and for FreeBSD. I also developed a domain-specific language for fingerprinting web applications using XPath and regular expressions. I work to increase my velocity and that of my team by aggressively finding ways to convert end-to-end tests into unit tests or integration tests. \\
\textbf{Tools used:} Java, JUnit, Eclipse, XML, Cucumber, git, JIRA, Maven, Python, JSON, AWS.
}

\vspace*{0.2\baselineskip}
\cventry{2012--2014}
{Security Researcher}
{Rapid7}
{}{}
{
As a member of the vulnerability coverage team for Rapid7 Nexpose, I was responsible for writing and maintaining automation which scraped the web for new vulnerabilities, identified the software versions in which they were fixed, and created vulnerability content based on this information.  In this role, I also wrote extensions to Nexpose to identify various software artifacts running on customer systems, and extended Nexpose to make writing new vulnerability checks easier.  The team followed an integrated development model in which everyone was responsible for both development and testing, including the creation of test systems. The team and I pushed several of our ad-hoc testing scenarios into more formal regression tests that could be run by developers who are not experts in vulnerability scanning, resulting in fewer escaped defects. \\
\textbf{Tools used:} Ruby, XML, XPath, regular expressions, Java, Jess, JUnit, Cucumber, VSphere, Mercurial, JIRA.
}


\vspace*{0.2\baselineskip}
\cventry{2008--2012}
{Staff Software Developer}
{IBM Canada}
{}{}
{
As a software developer for DB2 for Linux, Unix, and Windows at IBM Canada, I contributed to the DB2 9.7, 9.8, and 10.1 releases. I worked on the BufferPool Services team, which was responsible for the physical storage of data on disk (tablespaces, storage groups, etc.), bringing that data into memory as pages, and ensuring the integrity of the data in a highly concurrent environment. Much of the work involved debugging race conditions, including races involving storage shared across multiple computers, which could lead to crashes or database corruptions if not fixed. As a specialist in on-disk storage, I helped bring the multi-temperature storage feature to market in DB2 10.1, including creating DDL statements for manipulating storage groups. Additionally, I took ownership of a storage-based set of regression tests, and improved their usability by labeling test scenarios of most importance to different groups (e.g. backup and recovery). \\
\textbf{Tools used:} C/C++, gdb, Perl, ClearCase, ClearQuest. 
}

\section{Education}
\cventry{2003-2005}{M.Sc. in Computer Science}{University of Toronto}{2005}{}{}
\cventry{1999-2003}{B.Sc. in Mathematics and Computer Science}{Brandon University}{2003}{}{}

\section{Certifications}
\cventry{2012-2014}{Certified ScrumMaster}{Scrum Alliance, Inc.}{}{}{}

\section{Publications}

\cventry{2008}
{\textbf{Thomas E. Hart}\textnormal{, Marsha Chechik, and David Lie}}
{Security Benchmarking using Partial Verification}
{In Proc. HotSec’08}
{}{}{}

\cventry{2008}
{\textbf{Thomas E. Hart}\textnormal{, Kelvin Ku, David Lie, Marsha Chechik, and Arie Gurfinkel}}
{Augmenting Counterexample-Guided Abstraction Refinement with Proof Templates}
{In Proc. ASE’08}
{}{}{}

\cventry{2006}
{\textbf{Thomas E. Hart}\textnormal{, Paul E. McKenney, and Angela Demke Brown}}
{Making Lockless Synchronization Fast: Performance Implications of Memory Reclamation}
{In Proc. IPDPS'06}
{}{}{}

\section{Awards}
\cventry{2011}{First Place, Area 22 Toastmasters International Speech Contest}{}{}{}{}
\cventry{2006}{Best Paper Award, IPDPS 2006}{}{}{}{}
\cventry{2005,2006,2007}{T-Holder’s Award for Academic Excellence}{}{}{}{}
\cventry{2003-2007}{NSERC Canada Graduate Scholarship}{}{}{}{}
\cventry{2003}{Governor-General's Silver Medal}{}{}{}{}

\section{Personal Projects}
\cventry{2021}{https://www.drivethrurpg.com/product/353681/Paranormal-Affairs-Canada}{A Fate-based tabletop RPG of defending Canada from the supernatural}{}{}{}
\cventry{2020}{https://github.com/tomhart-msc/Fate-LaTeX-Template}{A \LaTeXe template for typesetting material for the Fate tabletop RPG}{}{}{}
\cventry{2020}{https://github.com/tomhart-msc/TroikaBag}{A Discord Bot for establishing turn order in the Troika RPG, written in Elixir}{}{}{}
\cventry{2019}{https://github.com/tomhart-msc/ova}{A set of helpers for running the OVA RPG, written in Elixir}{}{}{}
\cventry{2016}{https://github.com/tomhart-msc/hnefatafl}{A JavaScript implementation of Hnefatafl}{}{}{}

\end{document}
